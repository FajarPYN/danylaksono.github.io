<!--
Presentasi Sidang - Dany Laksono
Using GoogleIO Slide by Eric Bidelman and Luke MahÃ©
-->

<!DOCTYPE html>
<html>
<head>
  <title></title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
  <!--This one seems to work all the time, but really small on ipad-->
  <!--<meta name="viewport" content="initial-scale=0.4">-->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <link rel="stylesheet" media="all" href="theme/css/default.css">
  <link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css">
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="js/slides" src="js/require-1.0.8.min.js"></script>
  <style>	  
   figure {
    display: inline-block;
    margin: 20px; 
    }
	figure img {
			vertical-align: top;
			max-width:100%;
			transition: -webkit-transform 0.25s ease;
	}
		
	figure img:hover {
		 display: inline;
		-webkit-transform: scale(2);
		
		
	}
	
	figure img.noTransition {
    -moz-transition: none;
    -webkit-transition: none;
    -o-transition: color 0 ease-in;
    transition: none;
	}
		
	figure figcaption {
		font-size:14px !important;
		padding-top:5px;
		font-style: italic;
		text-align:center;
	}
	
   
  </style>
</head>
<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide id="depan" class="logoslide nobackground">
    <article class="flexbox vcenter">
      <span><img src="images/UGM_geomatics_logo2.png"></span>
    </article>
  </slide>

  <slide class="title-slide segue nobackground">
    <aside class="gdbar"><img src="images/ugm_icon_128.png"></aside>
    <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
    </hgroup>
  </slide>

  <slide>
    <hgroup>
      <h2>Thesis Proposal</h2>
      <h3> Mobile SfM for 3D Reconstruction: Implementation and Evaluation</h3>
    </hgroup>
    <article>
		<p><b>List of Contents</b></p>
      <div class="columns-2">
      <ul>
        <li>Fundamental Backgrounds</li>
         <ul>
            <li>Computer Vision (OpenCV)</li>
            <li>Sensors in Android</li>
            <li>HTML5 WebRTC</li>
            <li>Structure from Motion</li>
          </ul> 
        <li>Some of Earlier Works on SfM</li>
          <!--ul>
            <li>Softwares Implementing SfM Method</li>
            <li>SfM for Building Reconstruction Accuracy Assessment (2012)</li>
            <li>Live Dense Reconstruction with a Single Moving Camera (2010)</li>
            <li>Dense Tracking and Mapping in Real Time (DTAM) (2011)</li>
            <li>3D Reconstruction from Accidental Motion (2014)</li>
            <li>Building Rome in A Day (2014)</li>
            <li>Live Metric and Interactive 3D Reconstruction on Mobile Phones (2014)</li>
          </ul-->
        </li>

        <li>Thesis Structure</li>
        <ul>
            <li>Problems Statement</li>
            <li>Goals of Research</li>
            <li>Methods of Research</li>
            <li>Research Scope</li>
        </ul>         
      </ul>
      </div>
    </article>
  </slide>
  
  <slide class="segue dark nobackground">
    <aside class="gdbar"><img src="images/ugm_icon_128.png"></aside>
    <hgroup class="auto-fadein">
      <h2>Part I</h2>
      <h3>Fundamental Backgrounds</h3>
    </hgroup>
  </slide>
  
  <slide>
    <hgroup>
      <h2>Computer Vision</h2>
      <h3>What is Computer Vision?</h3>
    </hgroup>
    <article>      
      <ul>
        <li>Scientific field that includes methods for acquiring, processing, 
        analyzing, and understanding images from the real world in order to 
        produce numerical or symbolic information <a href="http://compsadda.com/books/sem8/cvref.pdf">(Sonka, 2008)</a></li>
        <li>Deals with different kinds of  <b>algorithm </b> to extract information from images</li>
        <li><b>Realtime/Post-processed</b> image analysis</li>
        <li>Example applications: Image Acquisition, Feature Extraction, Motion analysis, 
        Segmentation, face and letter recognition, 3D reconstruction, Robotic vision, Augmented Reality</li>
        <li>In short, Computer Vision: <b>giving eyes to computer</b></li>
        <li><b>OpenCV </b> is an example of OpenSource Computer Vision library which implements 
        lots of computer vision algorithm </li>
      </ul>  
    </article>
  </slide>
  
  <slide>
	<aside class="note">
      <section>
        <figure>
			<p>Another Example:</p>
			<a href='images/slides/gesture_interpretation.jpg' target="_self">Gesture Interpretation</a>			
		</figure>
      </section>
    </aside>  
    <hgroup>
      <h2>Computer Vision</h2>
      <h3>Example application of OpenCV</h3>
    </hgroup>
    <article> 
      <div class="columns-3">
        <figure style="max-width:28%">
			<img src='images/slides/tree_count.png' alt='missing' />
			<figcaption>Tree counting</figcaption>
		</figure>
        <figure style="max-width:28%">
			<img src='images/slides/plate_recog.jpg' alt='missing' />
			<figcaption>Plate Number Recognition</figcaption>
		</figure>
		<figure style="max-width:28%">
			<img src='images/slides/canny_edges.png' alt='missing' />
			<figcaption>Canny Edge Detection</figcaption>
		</figure>
      </div>
      <div class="columns-3">
        <figure style="max-width:28%; vertical-align:top">
			<img src='images/slides/sift_matches.jpg' alt='missing' />
			<figcaption>SIFT feature matching</figcaption>
		</figure>
		<figure style="max-width:28%">
			<img src='images/slides/optical_flow.jpg' alt='missing' />
			<figcaption>Motion Tracking</figcaption>
		</figure>
		<figure style="max-width:28%">
			<img src='images/slides/hough_circle.jpg' alt='missing' />
			<figcaption>Hough Circle</figcaption>
		</figure>
	  </div>
    </article>
  </slide>
  
  <slide>
    <hgroup>
      <h2>Android Sensors</h2>
      <h3>Kinds of Android Sensors</h3>
    </hgroup>
    <article class="smaller">	  
		  <ul>
			<li>Android devices have built in sensors to enrich user's experience with the device</li>
			<li>These sensors record surrounding environment of an Android device</li>
			<li>Example of Android sensors: accelerometer, gyrometer, light, 
			magnetic, sound, temperature, air pressure, humidity, etc</li>
			<li>Android Developers can freely use sensor data obtained by these sensors for various purpose</li>
			<li>Example:</li>
				<ul>
					<li>Sensing user's motion and position</li>
					<li>Make device's sound louder on noisy surroundings</li>
					<li>Providing backlight in a room with poor lumination</li>
					<li>Using magnetic sensor to give estimation of magnetic north </li>	
				</ul>
			<li>Not all sensors are available on each device, but basically orientation/accelerometer 
			sensor are common even in low-cost Android devices</li>
		  </ul>
    </article>
  </slide>
    
  <slide>
    <hgroup>
      <h2>Android Sensors</h2>
    </hgroup>
    <article class="flexbox vcenter">
      <img class="noTransition"  src="images/slides/android_sensors.jpg" alt="Description" title="Description">
    </article>
  </slide>
  
    <slide>
    <hgroup>
      <h2>HTML5 WebRTC</h2>
      <h4>What is WebRTC?</h4>
    </hgroup>
    <article>	  
		  <ul>
			<li>WebRTC (Real-Time Communication) is a new standard for online data transmission, based on HTML5 </li>
			<li>WebRTC allows single connection, <b>real-time P2P</b> two way communication between server and client,
			 which is not possible before </li>
			<li>Can be used for <b> data exchange </b> between browser, since it is fully supported by HTML5 Standards</li>
			<li>Simple implementation, using <b>Javascript API </b> without any needs of plugin</li>
			<li>Revolutionize realtime communication technology</li>
			<li>Example of use:</li>
				<ul>
					<li>Realtime chat application</li>
					<li>In-browser video chat</li>
					<li>Realtime file transfer</li>
					<li>Realtime sensor monitoring</li>
				</ul>
			
		  </ul>
    </article>
  </slide>
  
  <slide>
    <hgroup>
      <h2>HTML5 WebRTC</h2>
    </hgroup>
    <article  class="flexbox vcenter" style="margin-top:0">	  
		  <a style="font-size:100px" href="http://localhost:8080/">  Demo </a>
    </article>
  </slide>
  
  
    <slide>
    <hgroup>
      <h2>Structure from Motion</h2>
      <h3>What is SfM?</h3>
    </hgroup>
    <article class="smaller">
		<div class="columns-2">	  
		  <ul>
			<li>Structure from Motion: A workflow for estimating three-dimensional structures from two-dimensional image sequences </li>
			<li>part of Computer vision algorithm <b>Structure from-X</b></li>
			<li>Based on Multi-view stereo: we can see an object's structure when it's moving</li>
			<li>Works with either calibrated or uncalibrated camera </li>
			<li>Lies on Computer vision algorithm for <b>keypoint matching </b> (commonly used: SIFT, SURF, ORB, etc)</li>
			<li>No need for camera position and orientation data to solve point's coordinate, the pose is solved iteratively based on 
			the relative pose of first two images</li>
		  </ul>
		  <ul>
			<img style="width:100%" class="noTransition"  src='images/slides/move_sfm.gif' alt='missing' onmouseover="ngambang(this);" onmouseout="gakngambang(this);" />
			<script>
				function ngambang(element) {
					element.setAttribute('src', 'images/slides/move_sfm.gif');
				}
				function gakngambang(element) {
					element.setAttribute('src', 'images/slides/move_sfm_static.gif');
				}
			</script>
			
		  </ul>
		</div>
    </article>
  </slide>
  
  <slide class="fill nobackground" style="background-image:url(images/slides/johannes_zahn.png); 
	background-size : 60% auto; background-position: center; " >
    <hgroup>
    </hgroup>
    <footer class="source black"><i>Johannes Zahn <br/> "The Radiating Eye" </i></footer>
  </slide>
  
  <slide>
    <hgroup>
      <h2>Structure from Motion</h2>
    </hgroup>
    <article class="flexbox vcenter">
      <img style="width:90%;" class="noTransition"  src="images/slides/sfm_concept.jpg" alt="Description" title="Description">
    </article>
  </slide>
  
  <slide>
    <hgroup>
      <h2>Structure from Motion</h2>
    </hgroup>
    <article class="flexbox vcenter">
      <img style="width:90%" class="noTransition"  src="images/slides/sfm_1.png" alt="Description" title="Description">
    </article>
  </slide>
  
  
  
  
  <slide class="segue dark nobackground">
    <aside class="gdbar"><img src="images/ugm_icon_128.png"></aside>
    <hgroup class="auto-fadein">
      <h2	>Part II</h2>
      <h3>Supporting Researchs</h3>
    </hgroup>
  </slide>
  
  <slide>
    <hgroup>
      <h2>Supporting Researchs</h2>
      <h3>Previous works on SfM</h3>
    </hgroup>
    <article>
		<p>Selected researchs which support this thesis:</p>	  
		  <ul>
			<li>Softwares Implementing SfM Method</li>
            <li>Comparison methods of terrestrial laser scanning, photogrammetry and tacheometry data for recording of cultural heritage buildings 
            <a href="http://www.isprs.org/proceedings/XXXVII/congress/5_pdf/38.pdf">
				 (Grussenmeyer, et. al, 2008) </a></li>
            <li>Live Dense Reconstruction with a Single Moving Camera
            <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539794"> (Newcombe and Davison, 2010)</a></li>
            <li>DTAM:Dense Tracking and Mapping in Real Time 
            <a href="https://www.doc.ic.ac.uk/~rnewcomb/Publications/newcombe_etal_iccv2011.pdf"> (Newcombe and Lovegrove, 2011)</a></li>
            <li>3D Reconstruction from Accidental Motion <a href="http://yf.io/p/tiny/tiny.pdf"> (Yu, 2014)</a></li>
            <li>Building Rome in A Day <a href="http://research.microsoft.com/pubs/156722/agarwal-rome-cacm11.pdf"> (Agarwal, 2013)</a></li>
            <li>Live Metric and Interactive 3D Reconstruction on Mobile Phones
             <a href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Tanskanen_Live_Metric_3D_2013_ICCV_paper.pdf"> (Tanskannen, 2013) </a></li>
		  </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Softwares implementing SfM pipelines</h2>
    </hgroup>
    <article>	  
		  <p>There are already some softwares, commercial or opensource, which implement SfM pipelines. For example:</p>	  
		  <ul>
            <li>Bundler (Opensource)</li>
            <li>Agisoft Photoscan (Commercial)</li>
            <li>Python Photogrammetry Toolbox (opensource)</li>
            <li>VisualSFM (together with PMVS/CMVS) (free)</li>
            <li>Microsoft Photosynth (Free with limitation)</li>
            <li>Pix4D Mapper (Commercial)</li>
            <li>Autodesk 123D (Commercial)</li>
            <li>etc</li>
		  </ul>
    </article>
  </slide>
  
  <slide>
    <hgroup>
      <h2>Comparison of laser scanning and SfM</h2>
    </hgroup>
    <article  class="flexbox vcenter" style="margin-top:0">	  
		  <img style="width:100%" class="noTransition"  src="images/slides/sfm_cloud_compare.png" alt="Description" title="Description">
		 
    <footer class="source">Grussenmeyer, et. al (2008)</footer>
    </article>
  </slide>
  
  <slide>
    <hgroup>
      <h2>Live Dense Reconstruction with a Single Moving Camera</h2>
    </hgroup>
    <article  class="flexbox vcenter" style="margin-top:0">	  
		 <video width="640" height="480" controls>
			<source src="file:///media/dany/Dokumen/__Thesis/Talks/Live Dense Reconstruction with a Single Moving Camera.mp4" type="video/mp4">
		  </video>
    <footer class="source"><a href="http://www.youtube.com/watch?v=CZiSK7OMANw">Newcombe and Davison (2010)</a></footer>
    </article>
  </slide>
  
   <slide>
    <hgroup>
      <h2>DTAM:Dense Tracking and Mapping in Real Time </h2>
    </hgroup>
    <article  class="flexbox vcenter" style="margin-top:0">	  
	<video width="640" height="480" controls>
			<source src="file:///media/dany/Dokumen/__Thesis/Talks/_DTAM- Dense Tracking and Mapping in Real-Time.mp4" type="video/mp4">
		  </video>
	<footer class="source"><a href="http://www.youtube.com/watch?v=Df9WhgibCQA">Newcombe and Lovegrove (2011)</a></footer>
    </article>
  </slide>
  
   
  <slide>
    <hgroup>
      <h2>3D Reconstruction from Accidental Motion  </h2>
    </hgroup>
    <article  class="flexbox vcenter" style="margin-top:0">	  
	<video width="640" height="480" controls>
			<source src="file:///media/dany/Dokumen/__Thesis/Talks/_3D Reconstruction from Accidental Motion.mp4" type="video/mp4">
		  </video>
    <footer class="source"><a href="http://www.youtube.com/watch?v=5Le0pxfRo80">Yu (2014)</a></footer>
    </article>
  </slide>
  
  <slide>
    <hgroup>
      <h2>Building Rome in A Day </h2>
    </hgroup>
    <article  class="flexbox vcenter" style="margin-top:0">	  
			 <img style="width:100%" class="noTransition"  src="images/slides/rome_in_a_day.jpg" alt="Description" title="Description"> 
    <footer class="source"><a href="http://www.youtube.com/watch?v=qYaU1GeEiR8&list=PLDFDB5B8C80DB3AD6">Agarwal (2013)</a></footer>
    </article>
  </slide>
  
    <slide>
    <hgroup>
      <h2>Live Metric and Interactive 3D Reconstruction on Mobile Phones</h2>
    </hgroup>
    <article  class="flexbox vcenter" style="margin-top:0">	  
		  <video width="640" height="480" controls>
			<source src="file:///media/dany/Dokumen/__Thesis/Talks/_Turning Mobile Phones into 3D Scanners.mp4" type="video/mp4">
		  </video>
    <footer class="source"><a href="http://www.youtube.com/watch?v=36PFT6SkYMI">Tanskannen (2013)</a></footer>
    </article>
  </slide>
  
     
  <slide class="segue dark nobackground">
    <aside class="gdbar"><img src="images/ugm_icon_128.png"></aside>
    <hgroup class="auto-fadein">
      <h2>Part III</h2>
      <h3>Thesis Structure</h3>
    </hgroup>
  </slide>
  
  <slide>
    <hgroup>
      <h2>Thesis Structure</h2>
      <h3>Content of Thesis</h3>
    </hgroup>
    <article>
		<p>This thesis will disscuss the implementation of mobile technology to obtain 3D reconstruction of buildings using SfM pipelines, 
		as well as conducting an evaluation of the result </p>	  
		<p>Below are the main structure of this thesis:  </p>
		   <ul>
            <li>Problems Statement</li>
            <li>Goals of Research</li>
            <li>Method of Research</li>
            <!--li>Research Scope</li-->
        </ul>   
    </article>
  </slide>
  
  
  <slide>
    <hgroup>
      <h2>Thesis Structure</h2>
      <h3>Problems Statement</h3>
    </hgroup>
    <article>
		<p>Problems/current status which motivate this research: </p>	  
		   <ul>
            <li>Current methods for obtaining 3D reconstruction of a single building is costly, equire trained personnel with high-tech, cumbersome equipment</li>
            <li>Rapid development in Structure from Motion algorithm for 3D reconstruction and recognition</li>
            <li>Technological advance of realtime data streaming</li>
            <li>Emerging trends of mobile handheld devices as part of lifestyle</li>
            <li>Limited research on the accuracy of SfM methods  </li>
            <li>Growing needs to assess the usability of SfM for 3D modeling of a building </li>
        </ul>   
    </article>
  </slide>
  
    
  <slide>
    <hgroup>
      <h2>Thesis Structure</h2>
      <h3>Research Objectives</h3>
    </hgroup>
    <article>
		<p>This research aims to implement use-case of mobile SfM and evaluate the use of
		 SfM pipeline in Android device to generate 3D model of a building</p>	  
		 <p>Another goals that are expected to be obtained from this research are as follow:</p>	  
		   <ul>
            <li>To develop a realtime, mobile SfM using state-of-the-art development in communication and computer vision technology</li>
            <li>To conduct evaluation and produce usability analysis of point cloud 
            generated from mobile SfM, with regards to other data acquisition methods</li>
        </ul>   
    </article>
  </slide>
  
    <slide>
    <hgroup>
      <h2>Thesis Structure</h2>
      <h3>Method of Research</h3>
    </hgroup>
    <article>
		<p>This research consist of three main parts:</p>
		<ul>
			<li>First Client, which is the Android device used for data acquisition</li>
			<li>Server, used to transmit data using Websocket protocol</li>
			<li>Second Client, which will receive image data from server and conduct SfM pipelines based on image sequences</li>
		</ul>	  
		<p> Handheld device (first client) will be used for data acquisition. The WebRTC server will
		 stream the data frame-by-frame to a second client which done all the processing to obtain
		 3D representation of surveyed building.</p>
		 <p>An evaluation of the 3D reconstruction will be conducted subsequently by comparing obtained point cloud with reference data</p>
    </article>
  </slide>
  
      <slide>
    <hgroup>
      <h2>Thesis Structure</h2>
      <h3>Method of Research</h3>
    </hgroup>
    <article class="smaller">
		<p>The SfM workflow that will be implemented is Calibrated Incremental 
		Structure from Motion following <a href="http://www.imm.dtu.dk/~aanes/phdthesis.pdf">Aanaes (2013)</a></p>
		<p>OpenCV will be the main library to implement the algorithm as follow:</p>
		<ul>
			<li>Camera calibration is conducted on the Android device in order to obtain Essential Matrix E</li>
			<li>Android device records and stream image data, as well as its orientation using WebRTC</li>
			<li>Two first images are selected, and a keypoint matching algorithm are employed to find matching points</li>
			<li>Relative pose will be calculated based on matched keypoints descriptor and Essential Matrix E, and used as Initial pose</li>
			<li>The process will be repeated iteratively to obtain pose-estimation of each images. 
			Data from Android Sensors will be used with Extended Kalman Filter for optimum pose-estimation </li>
			<li>Position of each point are calculated using bundle adjustment</li>
			<li>Sparse 3D point cloud from previous step will be used to generate dense point cloud using method explained in Pollefeys (1999)</li>
		</ul>	  
    </article>
  </slide>
  
  
  <slide class="thank-you-slide segue nobackground">
    <aside class="gdbar right"><img src="images/ugm_icon_128.png"></aside>
    <article class="flexbox vleft auto-fadein">
      <h2>&lt;Thank You!&gt;</h2>
      <p>Dany Puguh Laksono - Geomatics Engineering UGM.</p>
    </article>
    <p class="auto-fadein" data-config-contact>
      <!-- populated from slide_config.json -->
    </p>
  </slide>

  
  <slide class="backdrop"></slide>

</slides>

<!--script>
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-XXXXXXXX-1']);
_gaq.push(['_trackPageview']);

(function() {
  var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
  ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script-->

<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body>
</html>
